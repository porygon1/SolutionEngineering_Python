# ğŸ³ Docker Setup for Spotify Recommendation System

This guide explains how to run the Spotify Music Recommendation System using Docker.

## ğŸ“ Required Directory Structure

Before running, ensure your project has this structure:

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Raw data files
â”‚   â”‚   â”œâ”€â”€ spotify_tracks.csv
â”‚   â”‚   â”œâ”€â”€ spotify_artists.csv
â”‚   â”‚   â”œâ”€â”€ spotify_albums.csv
â”‚   â”‚   â”œâ”€â”€ lyrics_features.csv
â”‚   â”‚   â””â”€â”€ low_level_audio_features.csv
â”‚   â””â”€â”€ models/                       # Generated models from HDBSCAN notebook
â”‚       â”œâ”€â”€ hdbscan_model.pkl
â”‚       â”œâ”€â”€ knn_model.pkl
â”‚       â”œâ”€â”€ audio_embeddings.pkl
â”‚       â”œâ”€â”€ cluster_labels.pkl
â”‚       â””â”€â”€ song_indices.pkl
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ Models/
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ HDBSCAN_Clusters_KNN.ipynb
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ DOCKER_SETUP.md
```

## ğŸš€ Quick Start

### Step 1: Generate Models from HDBSCAN Notebook

**Important**: Before running the Docker application, you need to run the HDBSCAN notebook to generate the required model files.

1. Open `scripts/Models/HDBSCAN_Clusters_KNN.ipynb`
2. Run all cells to train the models
3. Ensure the following files are exported to `data/models/`:
   - `hdbscan_model.pkl` - HDBSCAN clustering model
   - `knn_model.pkl` - KNN recommendation model
   - `audio_embeddings.pkl` - Audio feature embeddings
   - `cluster_labels.pkl` - Cluster labels for each song
   - `song_indices.pkl` - Song metadata mapping

### Step 2: Start the Application

```bash
# Start the recommendation system
docker-compose up
```

### Step 3: Access the Application

- **Recommendation System**: http://localhost:8501
- **Health Check**: http://localhost:8501/_stcore/health

## ğŸ“‹ Available Services

### ğŸµ Streamlit Recommendation System
**Container**: `spotify-recommendation-system`
**Port**: 8501
**Purpose**: Main recommendation web application

```bash
# Start the Streamlit app
docker-compose up

# Run in background
docker-compose up -d

# View logs
docker-compose logs -f streamlit
```

## ğŸ”§ Model Requirements

The application expects these model files in `data/models/`:

| File | Description | Required |
|------|-------------|----------|
| `hdbscan_model.pkl` | HDBSCAN clustering model | Optional |
| `knn_model.pkl` | K-Nearest Neighbors model | âœ… Required |
| `audio_embeddings.pkl` | Feature embeddings | âœ… Required |
| `cluster_labels.pkl` | Cluster assignments | Optional |
| `song_indices.pkl` | Song metadata mapping | Optional |

**Note**: The app will work with just the KNN model and embeddings, but clustering features require the HDBSCAN model and labels.

## ğŸ” Monitoring and Debugging

### Check Service Status
```bash
docker-compose ps
```

### View Logs
```bash
# All services
docker-compose logs

# Real-time logs
docker-compose logs -f streamlit
```

### Health Checks
```bash
# Check if Streamlit is healthy
curl http://localhost:8501/_stcore/health

# Check container health
docker-compose ps
```

### Restart Services
```bash
# Restart
docker-compose restart

# Stop and start
docker-compose down && docker-compose up -d
```

## ğŸ› ï¸ Troubleshooting

### Models Not Found Error
1. Ensure raw data files exist in `data/raw/`
2. Run the HDBSCAN notebook completely:
   ```bash
   # Install notebook dependencies
   pip install -r scripts/Models/requirements.txt
   
   # Run Jupyter notebook
   jupyter notebook scripts/Models/HDBSCAN_Clusters_KNN.ipynb
   ```
3. Check model files were created:
   ```bash
   ls -la data/models/
   ```

### Missing Essential Models
The app requires at minimum:
- `knn_model.pkl`
- `audio_embeddings.pkl`

If these are missing, add export code to your notebook:
```python
# At the end of your HDBSCAN notebook
import pickle
import os

os.makedirs('../../data/models', exist_ok=True)

# Export KNN model
with open('../../data/models/knn_model.pkl', 'wb') as f:
    pickle.dump(your_knn_model, f)

# Export embeddings
with open('../../data/models/audio_embeddings.pkl', 'wb') as f:
    pickle.dump(your_embeddings, f)
```

### Permission Issues
```bash
# Fix permissions on data directory
sudo chown -R $USER:$USER data/
chmod -R 755 data/
```

### Port Conflicts
Change ports in `docker-compose.yml` if 8501 is in use:
```yaml
ports:
  - "8502:8501"  # Change external port
```

### Memory Issues
- Increase Docker memory allocation (4GB+ recommended)
- Large audio embeddings may require more memory

## ğŸ§¹ Cleanup

### Remove Containers
```bash
docker-compose down
```

### Remove Containers and Volumes
```bash
docker-compose down -v
```

### Remove Images
```bash
docker-compose down --rmi all
```

### Full Cleanup
```bash
docker-compose down -v --rmi all
docker system prune -f
```

## ğŸ”§ Customization

### Environment Variables
Add to `docker-compose.yml` under `environment:`:

```yaml
environment:
  - STREAMLIT_SERVER_PORT=8501
  - STREAMLIT_SERVER_HEADLESS=true
```

### Volume Mounts
Modify volume mounts in `docker-compose.yml`:

```yaml
volumes:
  - ./custom_data:/app/data:ro
  - ./custom_models:/app/data/models:ro
```

## ğŸ“± Development Workflow

1. **Prepare Data**: Ensure raw data files are in `data/raw/`

2. **Generate Models**: 
   ```bash
   # Install dependencies
   pip install -r scripts/Models/requirements.txt
   
   # Run HDBSCAN notebook
   jupyter notebook scripts/Models/HDBSCAN_Clusters_KNN.ipynb
   ```

3. **Test Locally**:
   ```bash
   # Start application
   docker-compose up
   
   # Test at http://localhost:8501
   ```

4. **Production Deployment**:
   ```bash
   docker-compose up -d
   ```

## ğŸ¯ Features

The recommendation system provides:

- **ğŸŒ Global Recommendations**: Similar songs from the entire dataset
- **ğŸ¯ Cluster-Based Recommendations**: Songs from the same musical cluster
- **ğŸ” Search Functionality**: Find songs by name or artist
- **ğŸ“Š Similarity Visualization**: Visual representation of song similarity
- **ğŸ² Random Discovery**: Random song selection for exploration

This simplified setup focuses on the core HDBSCAN clustering and KNN recommendation functionality! 